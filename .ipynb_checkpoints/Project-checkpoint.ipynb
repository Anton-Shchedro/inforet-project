{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e61e96b-1de8-4bb6-8a65-edf8a14e5574",
   "metadata": {},
   "source": [
    "# Datasets preporation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2641f9-f728-4b4d-9673-73eee4a8e417",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The zip file contains a large json file structured as follows. There is a 'segments' key that contains a list of speeches from members of parliament from 1948 to 2020. There is a lot of meta-data associated with each speech.. For the project, all you need is the field 'text'. I suggest you split the file into multiple files one for each legislature. Consider only the speeches with the field 'score' greater than 2.5 (the other speeches are meaningless)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b492b3d-ddc0-424d-97fd-3dd949fcd325",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6c948-5120-4b8a-9cf0-09ed2932c3ba",
   "metadata": {},
   "source": [
    "## Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9842198e-19a6-4608-914f-1971c31b8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../speeches.json', \"r\") as read_file:\n",
    "    j = json.load(read_file)\n",
    "    \n",
    "text = pd.json_normalize(j, record_path =['segments'])\n",
    "text = text[text['score']>2.5]\n",
    "text = text.reset_index(drop=True)\n",
    "#dataset: text\n",
    "del j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48586505-9644-4ca6-9196-7c97a9da1aab",
   "metadata": {},
   "source": [
    "## Person Dataset (Info about deputy (Legislator) (dfp), senators (dfs) and ministers (dfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f19273-58b9-4c90-95b5-d34c311816de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info about deputy\n",
    "df1 = pd.read_csv('parlamentari0x.csv')\n",
    "df2 = pd.read_csv('parlamentari1x.csv')\n",
    "dfp = pd.concat([df1, df2], ignore_index=True)\n",
    "# transform date from int to date format\n",
    "dfp['inizioMandato'] = pd.to_datetime(dfp['inizioMandato'], format=\"%Y%m%d\")\n",
    "dfp['fineMandato'] = dfp['fineMandato'].fillna(20990101)  # if person is currently active use placeholder as end date \n",
    "dfp['fineMandato'] = pd.to_datetime(dfp['fineMandato'], format=\"%Y%m%d\")\n",
    "# loan info about senators\n",
    "df1 = pd.read_csv('senato0x.csv')\n",
    "df2 = pd.read_csv('senato1x.csv')\n",
    "dfs = pd.concat([df1, df2], ignore_index=True)\n",
    "dfs['inizioMandato'] = pd.to_datetime(dfs['inizioMandato'], format=\"%Y%m%d\")\n",
    "dfs['fineMandato'] = dfs['fineMandato'].fillna(20990101)  # if person is currently active use placeholder as end date \n",
    "dfs['fineMandato'] = pd.to_datetime(dfs['fineMandato'], format=\"%Y%m%d\")\n",
    "# load info about ministers\n",
    "df1 = pd.read_csv('ministri0x.csv')\n",
    "df2 = pd.read_csv('ministri1x.csv')\n",
    "dfm = pd.concat([df1, df2], ignore_index=True)\n",
    "# rename some colums (to be abble to concat)\n",
    "dfm = dfm.rename(columns={\"d\": \"persona\"})\n",
    "dfp = dfp.rename(columns={\"inizioMandato\": \"dataInizio\", \"fineMandato\": \"dataFine\"})\n",
    "dfs = dfs.rename(columns={\"inizioMandato\": \"dataInizio\", \"fineMandato\": \"dataFine\"})\n",
    "# replace ministers link to it's personal link (have same numerical number, need only to change prefix and remove '_xx')\n",
    "for i, d in dfm.iterrows():\n",
    "    m = re.search('deputato.rdf/d(.+?)_', d['persona'])\n",
    "    dfm.at[i,'persona'] = 'http://dati.camera.it/ocd/persona.rdf/p'+m.group(1)\n",
    "# transform date from int to date format   \n",
    "dfm['dataInizio'] = pd.to_datetime(dfm['dataInizio'], format=\"%Y%m%d\")\n",
    "dfm['dataFine'] = dfm['dataFine'].fillna(20990101)\n",
    "dfm['dataFine'] = pd.to_datetime(dfm['dataFine'], format=\"%Y%m%d\")\n",
    "# need only some colums\n",
    "dfp = dfp[['persona','cognome','nome','dataInizio','dataFine']]\n",
    "dfm = dfm[['persona','cognome','nome','dataInizio','dataFine','carica','nomeOrganoGoverno']]\n",
    "# final concat into one df\n",
    "filtered_personnel = pd.concat([dfp, dfm, dfs], ignore_index=True)\n",
    "filtered_personnel = filtered_personnel.rename(columns={\"cognome\": \"surname\", \"nome\": \"name\"})\n",
    "filtered_personnel =  filtered_personnel[['persona','surname','name','dataInizio','dataFine','carica','nomeOrganoGoverno']]\n",
    "# dataset: filtered_personnel\n",
    "del df1, df2, dfp, dfs, dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010b8d7a-31b2-4c04-971b-bdaae132b371",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make a sample test dataset\n",
    "\n",
    "Just to make it easier to work or test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68b69e3-b350-4497-b978-84ea5dc3ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = text[['text','persona','date','surname','name']].sample(1000)\n",
    "text2 = text2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e191ea-eab3-4f0d-8ddb-0dae318309b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# First Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d8f21c-dd3f-4ba5-b164-689ce8e67666",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURNAME done\n",
      "NAME done\n",
      "TEXT done\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def words(text): \n",
    "    text = text.upper().replace(\"À\",\"A'\").replace(\"È\",\"E'\").replace(\"É\",\"E'\").replace(\"Ì\",\"I'\").replace(\"Í\",\"I'\").replace(\"Ò\",\"O'\").replace(\"Ó\",\"O'\").replace(\"Ù\",\"U'\").replace(\"Ú\",\"U'\").replace(\"Ü\",\"U'\")\n",
    "    return re.findall(r\"[A-Z'-]+\", text.upper())\n",
    "SURNAME = Counter(words(' '.join(filtered_personnel['surname'])))\n",
    "print(\"SURNAME done\")\n",
    "NAME = Counter(words(' '.join(filtered_personnel['name'])))\n",
    "print(\"NAME done\")\n",
    "t = ' '.join(text['text'])\n",
    "\n",
    "TEXT = Counter(words(t))\n",
    "print(\"TEXT done\")\n",
    "WORDS = SURNAME\n",
    "del t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a66b0b-f9e0-4e38-a7cd-b8270377baa7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = \"abcdefghijklmnopqrstuvwxyz'\".upper()\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f3d826-96b8-43db-8530-77af185aae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_by_surname(words,personnel, corr):\n",
    "    if len(words) > 2:\n",
    "        sur = personnel[(personnel[\"surname\"] == words[0].upper()) #first word is surname\n",
    "                       | (personnel[\"surname\"] == words[1].upper()) #second word is surname\n",
    "                       | (personnel[\"surname\"] == words[2].upper()) #third word is surname\n",
    "                       | (personnel[\"surname\"] == (words[0]+' '+words[1]).upper()) #surname by multiple words\n",
    "                       | (personnel[\"surname\"] == (words[1]+' '+words[2]).upper())] #surname by multiple words\n",
    "    elif len(words) == 2:\n",
    "        sur = personnel[(personnel[\"surname\"] == words[0].upper()) #first word is surname\n",
    "                       | (personnel[\"surname\"] == words[1].upper()) #second word is surname\n",
    "                       | (personnel[\"surname\"] == (words[0]+' '+words[1]).upper())] #surname by multiple words\n",
    "    else:\n",
    "        sur = personnel[(personnel[\"surname\"] == words[0].upper())] #first word is surname\n",
    "    if len(sur.index) == 0 and not corr:\n",
    "        corr = True\n",
    "        WORDS = SURNAME\n",
    "        words[0] = correction(words[0].upper())\n",
    "        if len(words) == 2:\n",
    "            words[1] = correction(words[1].upper())\n",
    "        elif len(words) > 2:\n",
    "            words[2] = correction(words[2].upper())\n",
    "        sur = find_by_surname(words,personnel,corr)\n",
    "    return sur\n",
    "\n",
    "def find_by_name(words,personnel,corr):\n",
    "    if len(words) > 2:\n",
    "        sur = personnel[(personnel[\"name\"] == words[0].upper()) #first word is name\n",
    "                       | (personnel[\"name\"] == words[1].upper()) #second word is name\n",
    "                       | (personnel[\"name\"] == words[2].upper()) #third word is name\n",
    "                       | (personnel[\"name\"] == (words[0]+' '+words[1]).upper()) #name by multiple words\n",
    "                       | (personnel[\"name\"] == (words[1]+' '+words[2]).upper())] #name by multiple words\n",
    "    elif len(words) == 2:\n",
    "        sur = personnel[(personnel[\"name\"] == words[0].upper()) #first word is name\n",
    "                       | (personnel[\"name\"] == words[1].upper()) #second word is name\n",
    "                       | (personnel[\"name\"] == (words[0]+' '+words[1]).upper())] #name by multiple words\n",
    "    else:\n",
    "        sur = personnel[(personnel[\"name\"] == words[0].upper())] #first word is name\n",
    "    if len(pd.unique(sur[\"name\"])) > 1 and len(words) > 1: # if more then one surename in result, reduce up to first in text\n",
    "        sur = find_by_name(words[0:-1],sur, False)\n",
    "    if len(sur.index) == 0 and not corr:\n",
    "        corr = True\n",
    "        WORDS = NAME\n",
    "        words[0] = correction(words[0].upper())\n",
    "        if len(words) == 2:\n",
    "            words[1] = correction(words[1].upper())\n",
    "        elif len(words) > 2:\n",
    "            words[2] = correction(words[2].upper())\n",
    "        sur = find_by_surname(words,personnel,corr)\n",
    "    return sur\n",
    "\n",
    "def find_person(text, date, personnel):\n",
    "    global phase  # used for debug and error log\n",
    "    global l # size of text dataset\n",
    "    phase = \"char_replace\"\n",
    "    text = text.replace(\"À\",\"A'\")\n",
    "    text = text.replace(\"È\",\"E'\")\n",
    "    text = text.replace(\"É\",\"E'\")\n",
    "    text = text.replace(\"Ì\",\"I'\")\n",
    "    text = text.replace(\"Ò\",\"O'\")\n",
    "    text = text.replace(\"Ó\",\"O'\")\n",
    "    text = text.replace(\"Ù\",\"U'\")\n",
    "    phase = \"words\"\n",
    "    words = regex.sub('', text).split(maxsplit = 4)\n",
    "    if len(words)==0:   # text is empty\n",
    "        l -= 1\n",
    "        return None\n",
    "    while (not words[0].isalpha()):  # use only words.\n",
    "        words.pop(0)\n",
    "        if len(words) == 0:\n",
    "            return None\n",
    "        t = ' '.join(words)    # this and next line is used just because i limit split up to 4\n",
    "        words = regex.sub('', t).split(maxsplit = 4)\n",
    "    phase = \"date_search\"\n",
    "    date = personnel[(personnel[\"dataInizio\"] <= date) & (personnel[\"dataFine\"] >= date)]  # start with persons in possitions in a date of speech\n",
    "    if len(date.index) >= 1:\n",
    "        phase = \"sur_search\"\n",
    "        sur = find_by_surname(words, date, False)\n",
    "        #print(sur)\n",
    "        if len(sur.index) == 1:\n",
    "            return sur.iloc[0]['persona']\n",
    "        elif len(sur.index) > 1:\n",
    "            if len(pd.unique(sur['persona'])) == 1:\n",
    "                return sur.iloc[0]['persona']\n",
    "            elif len(words) > 1:\n",
    "                phase = \"name_search\"\n",
    "                name = find_by_name(words, sur, False)\n",
    "                #print('-------------------')\n",
    "                #print(name)\n",
    "                if len(name.index) == 1 or (len(name.index) > 1 and len(pd.unique(name['persona']))):\n",
    "                    return name.iloc[0]['persona']\n",
    "    else:#No person found with that surename with correction\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a44a0b3-e247-49bc-8c7b-797da6911b4d",
   "metadata": {},
   "source": [
    "I use here a sumple of the text dataset.\n",
    "\n",
    "To use whole dataset, change 2 lines:\n",
    "\n",
    "l = len(text2.index)\n",
    "\n",
    "to \n",
    "\n",
    "l = len(text.index)\n",
    "\n",
    "\n",
    "\n",
    "and \n",
    "\n",
    "\n",
    "\n",
    "for index, row in text2.iterrows():\n",
    "\n",
    "to \n",
    "\n",
    "for index, row in text.iterrows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04daf91-c4b1-4343-acf9-7637a88c3c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     1000\n",
       "unique       2\n",
       "top       True\n",
       "freq       786\n",
       "Name: Correct, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(text2.index)\n",
    "res = []\n",
    "errors = []\n",
    "\n",
    "regex = re.compile(\"[^a-zA-Z -']\")\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for index, row in text2.iterrows():\n",
    "    global phase\n",
    "    try:\n",
    "        person = find_person(row['text'], row['date'], filtered_personnel)\n",
    "    except:\n",
    "        errors.append({'index':index, 'text':row['text'], 'phase':phase})\n",
    "        continue\n",
    "    predicted = filtered_personnel.loc[filtered_personnel['persona'] == person]\n",
    "    if person is not None:\n",
    "        pred_surname = predicted.iloc[0]['surname']\n",
    "        pred_name = predicted.iloc[0]['name']\n",
    "    else:\n",
    "        pred_surname = None\n",
    "        pred_name = None\n",
    "    if row[\"persona\"] == person:\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    \n",
    "    res.append({\"True persona\": row[\"persona\"], \"True name\": row[\"name\"], \"True surname\": row[\"surname\"],\n",
    "                \"Text\":row[\"text\"],  \"Correct\":correct, \"Predicted persona\": person,\n",
    "                \"Predicted surname\": pred_surname, \n",
    "                \"Predicted name\": pred_name})\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Done record '+str(index))\n",
    "    ind += 1\n",
    "    print(str(ind)+'/'+str(l)+'    '+str((ind/l)*100)+'%')\n",
    "            \n",
    "clear_output(wait=True)\n",
    "print('Done')\n",
    "result = pd.DataFrame.from_dict(res)\n",
    "result['Correct'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff8676-4a44-4d31-babf-13bf27c2f097",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Second Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b22fae60-f018-4356-a937-9382b1e0fb89",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURNAME done\n",
      "NAME done\n",
      "TEXT done\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def words(text): \n",
    "    text = text.upper().replace(\"À\",\"A'\").replace(\"È\",\"E'\").replace(\"É\",\"E'\").replace(\"Ì\",\"I'\").replace(\"Í\",\"I'\").replace(\"Ò\",\"O'\").replace(\"Ó\",\"O'\").replace(\"Ù\",\"U'\").replace(\"Ú\",\"U'\").replace(\"Ü\",\"U'\")\n",
    "    return re.findall(r\"[A-Z'-]+\", text.upper())\n",
    "SURNAME = Counter(words(' '.join(filtered_personnel['surname'])))\n",
    "print(\"SURNAME done\")\n",
    "NAME = Counter(words(' '.join(filtered_personnel['name'])))\n",
    "print(\"NAME done\")\n",
    "t = ' '.join(text['text'])\n",
    "\n",
    "TEXT = Counter(words(t))\n",
    "print(\"TEXT done\")\n",
    "WORDS = SURNAME\n",
    "del t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88c95608-62b3-4807-9cc2-1a6d330dd3da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = \"abcdefghijklmnopqrstuvwxyz'\".upper()\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb31ec-4cf8-4b88-b677-2d3c39f4b4bb",
   "metadata": {},
   "source": [
    "create one-gramms used in word-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1b3e1a-195b-4bd5-9793-7329fa1d2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"one-grams.txt\", 'w') as f:\n",
    "    c = TEXT+SURNAME+NAME\n",
    "    for k,v in  c.most_common():\n",
    "        f.write( \"{}\\t{}\\n\".format(k.lower(),v) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cade5b41-79b9-4618-b6cb-3db926bb8ac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segment\n",
    "def find_by_surname(text,personnel, corr):\n",
    "    import pandas as pd\n",
    "    data = []\n",
    "    for i, s in personnel.iterrows():\n",
    "        if s['surname'] in text:\n",
    "            data.append(s)\n",
    "    sur = pd.DataFrame(data)\n",
    "    #if len(pd.unique(sur[\"surname\"])) > 1 and len(words) > 1: # if more then one surename in result, reduce up to first in text\n",
    "        #len(words) just as hedge against error\n",
    "    #    sur = find_by_surname(words[0:-1],sur, False)\n",
    "    if len(sur.index) == 0 and not corr:\n",
    "        WORDS = SURNAME+TEXT\n",
    "        word = regex.sub('', text).split()\n",
    "        for i, w in enumerate(word):\n",
    "            word[i] = correction(w)\n",
    "        sur = find_by_surname(' '.join(word),personnel,True)\n",
    "    return sur\n",
    "\n",
    "def find_by_name(text,personnel,corr):\n",
    "    import pandas as pd\n",
    "    data = []\n",
    "    for i, s in personnel.iterrows():\n",
    "        if s['name'] in text:\n",
    "            data.append(s)\n",
    "    sur = pd.DataFrame(data)\n",
    "    return sur\n",
    "\n",
    "def find_person(text, date, personnel):\n",
    "    import pandas as pd\n",
    "    import segment\n",
    "    global phase\n",
    "    global l\n",
    "    phase = \"char_replace\"\n",
    "    text = text.replace(\"À\",\"A'\")\n",
    "    text = text.replace(\"È\",\"E'\")\n",
    "    text = text.replace(\"É\",\"E'\")\n",
    "    text = text.replace(\"Ì\",\"I'\")\n",
    "    text = text.replace(\"Ò\",\"O'\")\n",
    "    text = text.replace(\"Ó\",\"O'\")\n",
    "    text = text.replace(\"Ù\",\"U'\")\n",
    "    \n",
    "    # take only up to 20 first words\n",
    "    word = regex.sub('', text).split()\n",
    "    average = sum(len(w) for w in word) / len(word)\n",
    "    if average < 4:\n",
    "        if len(word) >= 120: #avarage 6-8 letters in italian word (6*20 = 120), but segment have limit of 100\n",
    "            seg = segment.segment(''.join(word[0:60]))\n",
    "        else:\n",
    "            seg = segment.segment(''.join(word))\n",
    "        text = ' '.join(seg)\n",
    "    elif len(word) >= 20:\n",
    "        text = ' '.join(word[0:20])\n",
    "    else:\n",
    "        text = ' '.join(word)\n",
    "    #print(text)\n",
    "    phase = \"date_search\"\n",
    "    date = personnel[(personnel[\"dataInizio\"] <= date) & (personnel[\"dataFine\"] >= date)]\n",
    "    if len(date.index) >= 1:\n",
    "        phase = \"sur_search\"\n",
    "        sur = find_by_surname(text.upper(), date, False)\n",
    "        phase = \"after_sur_search\"\n",
    "        #print(sur)\n",
    "        if len(sur.index) == 0:\n",
    "            return None\n",
    "        elif (len(sur.index) == 1) or (len(pd.unique(sur['persona'])) == 1):\n",
    "            return sur.iloc[0]['persona']\n",
    "        else:\n",
    "            if len(sur['surname'].value_counts()) > 1:\n",
    "                word = regex.sub('', text.upper()).split()\n",
    "                sur2 = pd.DataFrame({'A' : []})\n",
    "                i = 0\n",
    "                t = ''\n",
    "                while(sur2.empty and (i < 20 and i < len(word))): #limit of frase up to 20 words\n",
    "                    t = t + ' ' + word[i]\n",
    "                    sur2 = find_by_surname(t,sur,False) # check what surname is appering first in text \n",
    "                    i+=1\n",
    "                sur = sur2\n",
    "                if sur.empty:\n",
    "                    return None\n",
    "            #print(sur)\n",
    "            if len(pd.unique(sur['persona'])) == 1:\n",
    "                return sur.iloc[0]['persona']\n",
    "            else:\n",
    "                phase = \"name_search\"\n",
    "                name = find_by_name(text.upper(), sur, False)\n",
    "                #print('-------------------')\n",
    "                #print(name)\n",
    "                if len(name.index) == 1 or (len(name.index) > 1 and len(pd.unique(name['persona']))==1):\n",
    "                    return name.iloc[0]['persona']\n",
    "    else:#No person found with that surename with correction\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397c21ad-dc53-4695-a945-d558bcebd5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      999\n",
       "unique       2\n",
       "top       True\n",
       "freq       728\n",
       "Name: Correct, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(text2.index)\n",
    "res = []\n",
    "errors = []\n",
    "\n",
    "regex = re.compile(\"[^a-zA-Z -']\")\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for index, row in text2.iterrows():\n",
    "    global phase\n",
    "    try:\n",
    "        person = find_person(row['text'], row['date'], filtered_personnel)\n",
    "    except:\n",
    "        errors.append({'index':index, 'text':row['text'], 'phase':phase})\n",
    "        continue\n",
    "    predicted = filtered_personnel.loc[filtered_personnel['persona'] == person]\n",
    "    if person is not None:\n",
    "        pred_surname = predicted.iloc[0]['surname']\n",
    "        pred_name = predicted.iloc[0]['name']\n",
    "    else:\n",
    "        pred_surname = None\n",
    "        pred_name = None\n",
    "    if row[\"persona\"] == person:\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    \n",
    "    res.append({\"True persona\": row[\"persona\"], \"True name\": row[\"name\"], \"True surname\": row[\"surname\"],\n",
    "                \"Text\":row[\"text\"],  \"Correct\":correct, \"Predicted persona\": person,\n",
    "                \"Predicted surname\": pred_surname, \n",
    "                \"Predicted name\": pred_name})\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Done record '+str(index))\n",
    "    ind += 1\n",
    "    print(str(ind)+'/'+str(l)+'    '+str((ind/l)*100)+'%')\n",
    "            \n",
    "clear_output(wait=True)\n",
    "print('Done')\n",
    "result = pd.DataFrame.from_dict(res)\n",
    "result['Correct'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf391a-b6b6-46a6-af5a-63a7c1cf4c79",
   "metadata": {},
   "source": [
    "# Third Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04656ac-010e-42db-a2e7-17aa5cfe8812",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURNAME done\n",
      "NAME done\n",
      "TEXT done\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def words(text): \n",
    "    text = text.upper().replace(\"À\",\"A'\").replace(\"È\",\"E'\").replace(\"É\",\"E'\").replace(\"Ì\",\"I'\").replace(\"Í\",\"I'\").replace(\"Ò\",\"O'\").replace(\"Ó\",\"O'\").replace(\"Ù\",\"U'\").replace(\"Ú\",\"U'\").replace(\"Ü\",\"U'\")\n",
    "    return re.findall(r\"[A-Z'-]+\", text.upper())\n",
    "SURNAME = Counter(words(' '.join(filtered_personnel['surname'])))\n",
    "print(\"SURNAME done\")\n",
    "NAME = Counter(words(' '.join(filtered_personnel['name'])))\n",
    "print(\"NAME done\")\n",
    "t = ' '.join(text['text'])\n",
    "\n",
    "TEXT = Counter(words(t))\n",
    "print(\"TEXT done\")\n",
    "WORDS = SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ce9963-7681-4faa-9fad-257f9a85c495",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = \"abcdefghijklmnopqrstuvwxyz'\".upper()\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8adfde28-11bc-4b6a-b31c-f551a2d0c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = filtered_personnel[\"surname\"].value_counts()\n",
    "with open(\"surname2-one-grams.txt\", 'w') as f:\n",
    "    for k,v in s.iteritems():\n",
    "        k = k.replace(\"À\",\"A'\").replace(\"È\",\"E'\").replace(\"É\",\"E'\").replace(\"Ì\",\"I'\").replace(\"Í\",\"I'\").replace(\"Ò\",\"O'\").replace(\"Ó\",\"O'\").replace(\"Ù\",\"U'\").replace(\"Ú\",\"U'\").replace(\"Ü\",\"U'\")\n",
    "        string = k.lower() + \"\\t\\t\" + str(v) + \"\\n\"\n",
    "        f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437be32f-ce18-432d-bc71-662b1e4b0aff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import segment2_sur\n",
    "\n",
    "def find_by_surname(text,personnel, corr):\n",
    "    import pandas as pd\n",
    "    data = []\n",
    "    for i, s in personnel.iterrows():\n",
    "        if s['surname'] in text:\n",
    "            data.append(s)\n",
    "    sur = pd.DataFrame(data)\n",
    "    if len(sur.index) == 0 and not corr:\n",
    "        WORDS = SURNAME+TEXT\n",
    "        word = regex.sub('', text).split()\n",
    "        for i, w in enumerate(word):\n",
    "            word[i] = correction(w)\n",
    "        sur = find_by_surname(' '.join(word),personnel,True)\n",
    "    return sur\n",
    "\n",
    "def find_by_surname_2(text,personnel, corr):\n",
    "    import segment2_sur\n",
    "    import pandas as pd\n",
    "    global phase\n",
    "    phase = 'sur_start'\n",
    "    #print(phase)\n",
    "    data = []\n",
    "    phase = 'sur_segment'\n",
    "    #print(phase)\n",
    "    seg = segment2_sur.segment(text)\n",
    "    sur = pd.DataFrame({'A' : []})\n",
    "    #print(seg)\n",
    "    phase = 'sur_loop'\n",
    "    #print(phase)\n",
    "    for s in seg:\n",
    "        p = personnel[(personnel[\"surname\"] == s.upper())]\n",
    "        sur = pd.concat([sur,p])\n",
    "    phase = 'sur_loop_end'\n",
    "    #print(phase)\n",
    "    if len(sur.index) == 0 and not corr:\n",
    "        phase = 'sur_corr'\n",
    "        #print(phase)\n",
    "        WORDS = SURNAME+TEXT\n",
    "        word = regex.sub('', text).split()\n",
    "        for i, w in enumerate(word):\n",
    "            word[i] = correction(w)\n",
    "        sur = find_by_surname_2(' '.join(word),personnel,True)\n",
    "    return sur\n",
    "\n",
    "def find_by_name(text,personnel,corr):\n",
    "    import pandas as pd\n",
    "    data = []\n",
    "    for i, s in personnel.iterrows():\n",
    "        if s['name'] in text:\n",
    "            data.append(s)\n",
    "    sur = pd.DataFrame(data)\n",
    "    return sur\n",
    "\n",
    "def find_person(text, date, personnel):\n",
    "    global phase\n",
    "    global l\n",
    "    import re\n",
    "    import segment\n",
    "    import pandas as pd\n",
    "    phase = \"char_replace\"\n",
    "    text = text.upper().replace(\"À\",\"A'\")\n",
    "    text = text.replace(\"È\",\"E'\")\n",
    "    text = text.replace(\"É\",\"E'\")\n",
    "    text = text.replace(\"Ì\",\"I'\")\n",
    "    text = text.replace(\"Ò\",\"O'\")\n",
    "    text = text.replace(\"Ó\",\"O'\")\n",
    "    text = text.replace(\"Ù\",\"U'\")\n",
    "    \n",
    "    # take only up to 20 first words\n",
    "    phase = \"segment_start\"\n",
    "    #print(phase)\n",
    "    regex = re.compile(\"[^a-zA-Z -']\")\n",
    "    phase = \"error1\"\n",
    "    #print(phase)\n",
    "    word = regex.sub('', text).split()\n",
    "    phase = \"error2\"\n",
    "    #print(phase)\n",
    "    average = sum(len(w) for w in word) / len(word)\n",
    "    phase = \"error3\"\n",
    "    #print(phase)\n",
    "    if average < 4:\n",
    "        phase = \"segment\"\n",
    "        #print(phase)\n",
    "        if len(word) >= 60: #avarage 6-8 letters in italian word (6*20 = 120), but segment have limit of 60\n",
    "            seg = segment.segment(''.join(word[0:60]))\n",
    "        else:\n",
    "            seg = segment.segment(''.join(word))\n",
    "        text = ' '.join(seg)\n",
    "    elif len(word) >= 20:\n",
    "        phase = \"segment2\"\n",
    "        #print(phase)\n",
    "        text = ' '.join(word[0:20])\n",
    "    else:\n",
    "        text = ' '.join(word)\n",
    "    #print(text)\n",
    "    phase = \"date_search\"\n",
    "    #print(phase)\n",
    "    date = personnel[(personnel[\"dataInizio\"] <= date) & (personnel[\"dataFine\"] >= date)]\n",
    "    if len(date.index) >= 1:\n",
    "        phase = \"sur_search\"\n",
    "        #print(phase)\n",
    "        sur = find_by_surname_2(text.upper(), date, False)\n",
    "        phase = \"sur_search_end\"\n",
    "        #print(phase)\n",
    "        #print(sur)\n",
    "        if len(sur.index) == 0:\n",
    "            return None\n",
    "        elif (len(sur.index) == 1) or (len(pd.unique(sur['persona'])) == 1):\n",
    "            return sur.iloc[0]['persona']\n",
    "        else:\n",
    "            phase = \"name_search\"\n",
    "            #print(phase)\n",
    "            name = find_by_name(text.upper(), sur, False)\n",
    "            #print('-------------------')\n",
    "            #print(name)\n",
    "            if len(name.index) == 1 or (len(name.index) > 1 and len(pd.unique(name['persona']))==1):\n",
    "                return name.iloc[0]['persona']\n",
    "            elif (len(name.index) > 1 and len(name['surname'].value_counts()) > 1):\n",
    "                phase = \"sur_search_2\"\n",
    "                #print(phase)\n",
    "                word = regex.sub('', text.upper()).split()\n",
    "                sur2 = pd.DataFrame({'A' : []})\n",
    "                i = 0\n",
    "                while(sur2.empty and (i < 20 and i < len(word))): #limit of frase up to 20 words\n",
    "                    sur2 = find_by_surname(' '.join(word[0:i]),name,False) # check what surname is appering first in text \n",
    "                    i+=1\n",
    "                sur = sur2\n",
    "                #print(\"----------\")\n",
    "                #print(sur)\n",
    "                if len(sur.index) == 0:\n",
    "                    return None\n",
    "                elif (len(sur.index) == 1) or (len(pd.unique(sur['persona'])) == 1):\n",
    "                    return sur.iloc[0]['persona']\n",
    "                else: return None\n",
    "            else: #difference between this else and elif is in dataframe used (in elif 'name', in else 'sur')\n",
    "                phase = \"sur_search_3\"\n",
    "                #print(phase)\n",
    "                word = regex.sub('', text.upper()).split()\n",
    "                sur2 = pd.DataFrame({'A' : []})\n",
    "                i = 0\n",
    "                while(sur2.empty and (i < 20 and i < len(word))): #limit of frase up to 20 words\n",
    "                    sur2 = find_by_surname(' '.join(word[0:i]),sur,False) # check what surname is appering first in text \n",
    "                    i+=1\n",
    "                sur = sur2\n",
    "                #print(\"----------\")\n",
    "                #print(sur)\n",
    "                if len(sur.index) == 0:\n",
    "                    return None\n",
    "                elif (len(sur.index) == 1) or (len(pd.unique(sur['persona'])) == 1):\n",
    "                    return sur.iloc[0]['persona']\n",
    "                else: return None\n",
    "    return None #No person found with that surename with correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cac3c48e-b06e-424e-a16c-8b7bc2212ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     1000\n",
       "unique       2\n",
       "top       True\n",
       "freq       647\n",
       "Name: Correct, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(text2.index)\n",
    "res = []\n",
    "errors = []\n",
    "\n",
    "regex = re.compile(\"[^a-zA-Z -']\")\n",
    "\n",
    "ind = 0\n",
    "\n",
    "for index, row in text2.iterrows():\n",
    "    global phase\n",
    "    try:\n",
    "        person = find_person(row['text'], row['date'], filtered_personnel)\n",
    "    except:\n",
    "        errors.append({'index':index, 'text':row['text'], 'phase':phase})\n",
    "        continue\n",
    "    predicted = filtered_personnel.loc[filtered_personnel['persona'] == person]\n",
    "    if person is not None:\n",
    "        pred_surname = predicted.iloc[0]['surname']\n",
    "        pred_name = predicted.iloc[0]['name']\n",
    "    else:\n",
    "        pred_surname = None\n",
    "        pred_name = None\n",
    "    if row[\"persona\"] == person:\n",
    "        correct = True\n",
    "    else:\n",
    "        correct = False\n",
    "    \n",
    "    res.append({\"True persona\": row[\"persona\"], \"True name\": row[\"name\"], \"True surname\": row[\"surname\"],\n",
    "                \"Text\":row[\"text\"],  \"Correct\":correct, \"Predicted persona\": person,\n",
    "                \"Predicted surname\": pred_surname, \n",
    "                \"Predicted name\": pred_name})\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Done record '+str(index))\n",
    "    ind += 1\n",
    "    print(str(ind)+'/'+str(l)+'    '+str((ind/l)*100)+'%')\n",
    "            \n",
    "clear_output(wait=True)\n",
    "print('Done')\n",
    "result = pd.DataFrame.from_dict(res)\n",
    "result['Correct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a804d-30cc-4607-8806-157ff2564c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
